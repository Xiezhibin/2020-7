# 新集群用户权限 队列权限 小结

## 租户建立

新集群通过kerberos进行网络安全认证，AD服务器 ip，19.112.16.18。

**Kerberos中的基本概念：**
1）KDC：密钥分发中心，负责管理发放票据，记录授权。
2）Realm：Kerberos管理领域的标识。
3）principal：当每添加一个用户或服务的时候都需要向kdc添加一条principal，principl的形式为：主名称／实例名@领域名。
4）主名称：主名称可以是用户名或服务名，表示是用于提供各种网络服务（如hdfs，yarn，hive）的主体。
5）实例名：实例名简单理解为主机名。



 **Kerberos安装**
7.2.1 server节点安装kerberos相关软件

```shell
#server节点安装kerberos相关软件

[root@hadoop102 ~]# yum install -y krb5-server krb5-workstation krb5-libs
#查看结果
[root@hadoop102 ~]# rpm -qa | grep krb5
krb5-workstation-1.10.3-65.el6.x86_64
krb5-libs-1.10.3-65.el6.x86_64
krb5-server-1.10.3-65.el6.x86_64

#client节点安装

[root@hadoop103 ~]# yum install -y krb5-workstation krb5-libs
[root@hadoop104 ~]# yum install -y krb5-workstation krb5-libs
#查看结果
[root@hadoop103 ~]# rpm -qa | grep krb5
krb5-workstation-1.10.3-65.el6.x86_64
krb5-libs-1.10.3-65.el6.x86_64

```

 **Kerberos配置**

Server需要配置两个文件 kdc.conf和krb5.conf;

kdc.conf

- realm名称，Kerberos支持多个realm，一般全用大写。
- acl_file:admin的用户权。
- admin_keytab:KDC进行校验的keytab。



**配置kerberos**

需要配置的文件有两个为kdc.conf和krb5.conf , 配置只是需要Server服务节点配置，即hadoop102.
1） kdc配置
[root@hadoop102 ~]# vim /var/kerberos/krb5kdc/kdc.conf
[kdcdefaults]
 kdc_ports = 88
 kdc_tcp_ports = 88
supported_enctypes:支持的校验方式，注意把aes256-cts去掉，JAVA使用aes256-cts验证方式需要安装额外的jar包，所有这里不用。
2） krb5文件配置说明：

default_realm：默认的realm，设置 Kerberos 应用程序的默认领域，必须跟要配置的realm的名称一致。
ticket_lifetime：表明凭证生效的时限，一般为24小时。
renew_lifetime ： 表明凭证最长可以被延期的时限，一般为一个礼拜。当凭证过期之后，对安全认证的服务的后续访问则会失败。
udp_preference_limit= 1：禁止使用 udp，可以防止一个 Hadoop 中的错误。
realms：配置使用的 realm，如果有多个领域，只需向 [realms] 节添加其他的语句。
domain_realm：集群域名与Kerberos realm的映射关系，单个realm的情况下，可忽略。
3）同步krb5到Client节点

同步krb5到Client节点



**文件同步脚本**

- 把当前文件同步到起到机器 xsync.sh

- 使用方法 sh xsync.sh + 参数1（文件名称） 

```shell
#使用方法 例子
将xsync.sh 和写有ip信息的文件host_ip.txt放入一个文件夹内
记录方式
第一列（同步机器ip） 第二列（域名） 第三列（用户名称）第四列（密码）
sh xsync.sh tran.csv
```

```shell
#! /bin/bash
# $#:表示传递给脚本或参数个数
#1若未传递参数直接退出
prcount=$#

if ((prcount==0)); then
echo on args;
exit;
fi

#2获取文件的名称
p1=$1
fname=`basename $p1`
echo fname=$fname

#3 获取上级目录的绝对路径
pdir=`cd -P $(dirname $p1); pwd`
echo pdir=$pdir

#4 获取当前用户名称
user=`whoami`

#5 循环
while read line;do
       #提取文件中的ip
       hostname=`echo $line | cut -d " " -f2`
       #提取文件中的用户名
       user_name=`echo $line | cut -d " " -f3`
       #提取文件中的密码
       pass_word=`echo $line | cut -d " " -f4`
       #提取文件中的用户名

       expect <<EOF
            #复制公钥到目标主机
            #spawn scp -r /etc/krb5.conf root@${hostname}:/etc/
            spawn rsync -rvl $pdir/$fname $user@$hostname:$pdir
            expect {
                    expect实现自动输入密码
                    "yes/no" { send "yes\n";exp_continue }
                    "password" { send "$pass_word\n";exp_continue }
                    eof
            }
EOF
done < /root/host_ip.txt
```



**新建用户脚本**

- sh Alter.sh    修改文件中的username(用户名)，passwd(密码)，group(组名称) ；

```shell
#使用方法 例子
#将Alter.sh 和写有ip信息的文件host_ip.txt放入一个文件夹内
while read line;do
        #提取文件中的ip
        hostname=`echo $line | cut -d " " -f2`
        #提取文件中的用户名
        user_name=`echo $line | cut -d " " -f3`
        #提取文件中的密码
        pass_word=`echo $line | cut -d " " -f4`
        expect <<EOF
                #复制公钥到目标主机
  spawn ssh root@${hostname} "groupadd test;useradd -g test -m test;echo test|passwd --stdin test;"                
                expect {
                        #expect实现自动输入密码
                        "yes/no" { send "yes\n";exp_continue }
                        "password" { send "$pass_word\n";exp_continue }
                        eof
                }
EOF
# 读取存储ip的文件，host_ip文件所在的目录地址
done < /root/host_ip.txt
```



### 租户建立

- 建立kerberos租户
- 赋予租户相应权限
- 建立集群节点linux用户

```shell
#登录KDC节点 建立xiezhibin用户
#通过kadmin.local,也可以通过kadmin 输⼊⽤户密码登录
kadmin.local: addprinc -randkey xiezhibin1@ZHIDAOAUTO.COM #新建的普通⽤户或⽤下⾯的命令⾏建⽴
#产⽣随机密码
#第⼆步导出keytab⽂件
kadmin.local: xst -k /root/xiezhibin.keytab it1@ZHIDAOAUTO.COM #导出keytab⽂件
##2
授予租户表访问权限（sentry) + spark3才支持
Sentry管理员用户hive通过beeline客户端连接HiveServer2
kinit -kt /root/file/hive.keytab hive/w3121912@ZHIDAOAUTO.COM
beeline -u "jdbc:hive://19.112.15.22:10000/bdata;principal=hive/w3121912@ZHIDAOAUTO.COM"
#新建租户xiezhibin，放入Ysfadmin组中；  
create role xiezhibin
GRANT ROLE  xiezhibin  TO GROUP  Ysfadmin;
#将GMAILs数据库的写权限授予xiezhibin
GRANT select ON DATABASE gmall TO ROLE xiezhibin;
#将表gmail中的某些字段权限授予给xiezhibin
REVOKE SELECT (<column name>) ON TABLE <table name> FROM ROLE <role name>;
#Column-level privileges can only be applied to tables, not partitions or views.
GRANT ALL ON URI 'hdfs://19.112.15.11/user/xiezhibin' TO ROLE xiezhibin;
SHOW GRANT ROLE xiezhibin

##3 hdfs权限管理 
sentry-hdfs-plugin 还在研究中
kinit -kt /root/hdfs.keytab hdfs/w3121912@ZHIDAOAUTO.COM
hadoop fs -mkdir /user/xiezhibin
hadoop df -R chown xiezhibin:Ysfadmin /user/xiezhibin/
hddoop df -R chmod 740 /user/xiezhibin/ #同组可以查看

##4 linux用户建立

sh Alter.sh    修改文件中的xiezhibin(用户名)，passwd(密码)，Ysfadmin(组名称)


```

### 动态资源管理

赋予该租户队列

- zeppelin集群用户  root.zeppelin.standby(临时队列)  root.zeppelin.ysfdata(大资源队列)
- 系统程序用户队列 root.users.XXX(用户名称) 【配置需要满足提交权限中有hive用户和XXX用户】
- 可根据day(查询脚本 早9点到晚9点)、night(系统同步任务 晚上11点到早7点)，default(其他时间)

#### Yarn资源配置

![preview](https://pic4.zhimg.com/v2-8702ce73f6febbb6cf22b268b5c45f5e_r.jpg)

**YARN的工作流程分为如下几个步骤：**

1. 用户向YARN中提交应用程序，其中包括ApplicationMaster程序、启动ApplicationMaster的命令、用户程序等；
2. ResourceManager为该应用程序分配第一个Container，并与对应的NodeManager通信，要求它在这个Container中启动应用程序的ApplicationMaster；
3. ApplicationMaster首先向ResourceManager注册，用户可以直接通过ResourceManager查看应用程序的运行状态，然后它将为各个任务申请资源，并监控它的运行状态，直到运行结束，即重复图中的步骤4～7；
4. ApplicationMaster采用轮询的方式通过RPC协议向ResourceMaster申请和领取资源；
5. 一旦ApplicationMaster申请到资源后，便与对应的NodeManager通信，要求它启动任务；
6. NodeManager为任务设置好运行环境（包括环境变量、JAR包、二进制程序等）后，将任务启动命令写到一个脚本中，并通过运行该脚本启动任务；
7. 各个任务通过某个RPC协议向ApplicationMaster汇报自己的状态和进度，以让ApplicationMaster随时掌握各个任务的运行状态，从而可以在任务失败时重新启动任务。在应用程序运行过程中，用户可以随时通过RPC向ApplicationMaster查询应用程序的当前运行状态；
8. 应用程序运行完成后，ApplicationMaster向ResourceManager注销并关闭自己。



**Fair Scheduler**

使用fair scheduler；以队列为基础维度进行资源调度，保证每个队列的资源上限

推荐队列 Dominant Resource Fairness  (DRF)

首先观察任务的主导资源（Dominant Resource）是内存还是cpu，选出主导资源，然后根据任务之间主导资源的占比来分配资源。

- job1所需内存资源占集群总内存3%，所需cpu资源占集群总cpu1%，因此job1的主导资源是内存，占比3%；
- job2所需内存资源占2%，所需cpu资源占6%，job2的主导资源是cpu，占比6%；
- 因此job1和job2申请资源比例为`3% : 6%`，也就是1：2，job2分配的container数量为job1的两倍。



#### 队列参数设置

-  **minResources**: minimum resources the queue is entitled to. For the single-resource fairness policy, only the **memory** is used, other resources are ignored. **If a queue’s minimum share is not satisfied, it will be offered available resources before any other queue under the same parent.**（最小值没有满足，其他父队列下的任务会提交到当前队列） Under the single-resource fairness policy, a queue is considered unsatisfied if its memory usage is below its minimum memory share. **Under dominant resource fairness, a queue is considered unsatisfied if its usage for its dominant resource with respect to the cluster capacity is below its minimum share for that resource.** If multiple queues are **unsatisfied** in this situation, **resources go to the queue with the smallest ratio between relevant resource usage and its minimum.** （进入资源使用率和其最小值的比例最小的队列）Note that it is possible for a queue that is below its minimum to not **immediately** get up to its minimum when an application is submitted to the queue, because already-running jobs may be using those resources.
- **maxResources**: maximum resources a queue can be allocated. A queue will not be assigned a container that would put its aggregate usage over this limit. This limit is enforced recursively, the queue will not be assigned a container if that assignment would put the queue or its parent(s) over the maximum resources.
- **weight**: to share the cluster non-proportionally with other queues. Weights default to 1, and a queue with weight 2 should receive approximately twice as many resources as a queue with the default weight.

